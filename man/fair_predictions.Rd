% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fair-predictions.R
\name{fair_predictions}
\alias{fair_predictions}
\title{fair_predictions}
\usage{
fair_predictions(
  data,
  X,
  Z,
  W,
  Y,
  x0,
  x1,
  BN = "",
  eval_prop = 0.25,
  lr = 0.001,
  lmbd_seq = c(0.1, 0.5, 1, 2, 5, 10),
  relu_eps = FALSE,
  patience = 100,
  py_seed = 123,
  method = c("medDML", "causal_forest"),
  model = c("ranger", "linear"),
  tune_params = FALSE,
  nboot1 = 1L,
  nboot2 = 100L,
  ...
)
}
\arguments{
\item{data}{Object of class \code{data.frame} containing the dataset.}

\item{X}{A \code{character} scalar giving the name of the
protected attribute. Must be one of the entries of \code{names(data)}.}

\item{Z}{A \code{character} vector giving the names of all mediators.}

\item{W}{A \code{character} vector giving the names of all confounders.}

\item{Y}{A \code{character} scalar giving the name of the outcome.}

\item{x0, x1}{Scalar values giving the two levels of the binary protected
attribute.}

\item{BN}{A character vector with any combination of entries
\code{"DE"}, \code{"IE"}, \code{"SE"} representing the business necessity set.}

\item{eval_prop}{Proportion of the data that should be used as a held-out
evaluation set for the purposes of early stopping in the neural network fit.}

\item{lr}{Learning rate of the fitting process (for Adam optimizer).}

\item{lmbd_seq}{A sequence of values of \eqn{\lambda}, the parameter value
which balances between the standard loss functions (cross-entropy for
classification; mean squared error for regression) and the causal loss, which
measures how closely satisfied the desired causal constraints are. See more
in the details.}

\item{relu_eps}{A special type of penalization that allows small deviations
from the causal constraints. Default is \code{FALSE}. When changing to \code{TRUE},
a different value of the \eqn{\lambda} may be more appropriate.}

\item{patience}{Number of epochs of patience before triggering early
stopping.}

\item{method}{A \code{character} scalar with three options:
\code{"debiasing"} for a one-step debiasing approach with underlying
\code{xgboost} learners, \code{"causal_forest"} for the
\code{\link[grf:causal_forest]{grf::causal_forest()}} method from the \code{grf} package, and
\code{"medDML"} for mediation double-machine learning.}

\item{model}{A \code{character} scalar taking values in
\code{c("ranger", "linear")}, indicating whether a tree-based learner is used
\code{\link[ranger:ranger]{ranger::ranger()}}, or if the fitted model should be linear. This parameter
is only relevant if \code{method == "medDML"}.}

\item{tune_params}{A \code{logical(1L)} indicating whether the parameters
should be tuned for the tree-based methods (only the \code{min.node.size}
parameter is tuned). Defaults to \code{FALSE}.}

\item{nboot1}{An \code{integer} scalar determining the number of outer
bootstrap repetitions, that is, how many times the fitting procedure is
repeated. Default is \code{1L}. This parameter is ignored if
\code{method == "debiasing"}.}

\item{nboot2}{An \code{integer} scalar determining the number of inner
bootstrap repetitions, that is, how many bootstrap samples are taken after
the potential outcomes are obtained from the estimation procedure.
Default is \code{100L}. This parameter is ignored if
\code{method == "debiasing"}.}

\item{...}{Further arguments passed to downstream model fitting functions.}
}
\value{
An object of class \code{fair_prediction} with elements:
\item{\code{yhat_meas}, \code{y_meas}}{Causal fairness summaries for
\eqn{\widehat{Y}} and \eqn{Y}.}
\item{\code{task_type}}{Fit type: regression/classification.}
\item{\code{train_data}, \code{eval_data}}{Training and evaluation data.}
\item{\code{lr}, \code{patience}, \code{BN}}{See input definitions.}
\item{\code{neural_models}}{A list of neural network models obtained during
the model fitting. Note that these are python objects.}
\item{\code{X, Z, W, Y}}{Names of protected attribute, confounders,
mediators, outcome.}
\item{\code{x0, x1}}{Levels of protected attribute.}
\item{\code{method}}{Estimation method. See \verb{@param method}.}
\item{\code{model}}{Model class for \code{method == "medDML"}.}
\item{cl}{Generating function call.}
\item{params}{If \code{tune_params == TRUE} in the function call, this object
is a list of optimal \code{min.node.size} values for each tree-based used
in the estimation procedure. See \code{faircause:::doubly_robust_med()} and
\code{faircause::crf_wrap()} for more details about the used objects.}
}
\description{
Implementation of the Fair Prediction algorithm described in Causal Fairness
Analysis (Plecko & Bareinboim 2024). Uses only plain \code{R}.
}
\details{
The procedure takes the data as an input, together with
the causal graph given by the Standard Fairness Model, and the choice of
the business necessity set. It outputs an S3 class object of type
\code{fair_prediction} which contains model fits that satisfy the desired causal
constraints. The optimized loss function is the following:
\deqn{L(y, \hat{y}) + \lambda \Big( | \text{NDE}_{x_0, x_1}(\hat{y}) - \eta_1 |
+ | \text{NIE}_{x_1, x_0}(\hat{y}) - \eta_2 | + | \text{Exp-SE}_{x_1}(\hat{y})
 - \eta_3 | + | \text{Exp-SE}_{x_0}(\hat{y}) - \eta_4 | \Big).}
\eqn{L(y, \hat{y})} is either cross-entropy (for classification) or mean
squared error (for regression). The values of \eqn{\eta_1, \eta_2, \eta_3,
\eta_4} are either 0 if the effect is not in the business necessity set, or
equal the effect estimate for the true outcome \eqn{Y} (if the effect is BN).
The fitting process is repeated over a range of \eqn{\lambda} values, which
can be controlled using the \code{lmbd_seq} argument.
The quality of the fit can be assessed by applying \code{autoplot()} to the S3
object. Predictions on test data can be obtained by applying \code{predict()}.
}
\references{
Plecko, D. & Bareinboim, E. (2022).
Causal Fairness Analysis \cr
}
\author{
Drago Plecko
}
