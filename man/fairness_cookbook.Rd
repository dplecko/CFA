% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fair-cause.R
\name{fairness_cookbook}
\alias{fairness_cookbook}
\title{fairness_cookbook}
\usage{
fairness_cookbook(
  data,
  X,
  Z,
  W,
  Y,
  x0,
  x1,
  method = c("debiasing", "causal_forest", "medDML"),
  model = c("ranger", "linear"),
  tune_params = FALSE,
  nboot1 = 1L,
  nboot2 = 100L,
  ...
)
}
\arguments{
\item{data}{Object of class \code{data.frame} containing the dataset.}

\item{X}{A \code{character} scalar giving the name of the
protected attribute. Must be one of the entries of \code{names(data)}.}

\item{Z}{A \code{character} vector giving the names of all mediators.}

\item{W}{A \code{character} vector giving the names of all confounders.}

\item{Y}{A \code{character} scalar giving the name of the outcome.}

\item{x0, x1}{Scalar values giving the two levels of the binary protected
attribute.}

\item{method}{A \code{character} scalar with three options:
\code{"debiasing"} for a one-step debiasing approach with underlying
\code{xgboost} learners, \code{"causal_forest"} for the
\code{\link[grf:causal_forest]{grf::causal_forest()}} method from the \code{grf} package, and
\code{"medDML"} for mediation double-machine learning.}

\item{model}{A \code{character} scalar taking values in
\code{c("ranger", "linear")}, indicating whether a tree-based learner is used
\code{\link[ranger:ranger]{ranger::ranger()}}, or if the fitted model should be linear. This parameter
is only relevant if \code{method == "medDML"}.}

\item{tune_params}{A \code{logical(1L)} indicating whether the parameters
should be tuned for the tree-based methods (only the \code{min.node.size}
parameter is tuned). Defaults to \code{FALSE}.}

\item{nboot1}{An \code{integer} scalar determining the number of outer
bootstrap repetitions, that is, how many times the fitting procedure is
repeated. Default is \code{1L}. This parameter is ignored if
\code{method == "debiasing"}.}

\item{nboot2}{An \code{integer} scalar determining the number of inner
bootstrap repetitions, that is, how many bootstrap samples are taken after
the potential outcomes are obtained from the estimation procedure.
Default is \code{100L}. This parameter is ignored if
\code{method == "debiasing"}.}

\item{...}{Further arguments passed to downstream model fitting functions.}
}
\value{
An object of class \code{faircause}, containing the following
elements:
\item{\code{measures}}{A \code{data.frame} containing the estimates for each
combination of measure/outer bootstrap repetition/inner bootstrap repetition.}
\item{\code{X, Z, W, Y}}{Names of the protected attribute, confounders,
mediators, and the outcome, respectively.}
\item{\code{x0, x1}}{Protected attribute levels.}
\item{\code{method}}{Method of estimation (see parameters above).}
\item{\code{model}}{Model class of the fit (relevant if
\code{method == "medDML"}, see parameters above).}
\item{cl}{The function call that generated the object.}
\item{params}{If \code{tune_params == TRUE} in the function call, this object
is a list of optimal \code{min.node.size} values for each tree-based used
in the estimation procedure. See \code{faircause:::doubly_robust_med()} and
\code{faircause::crf_wrap()} for more details about the used objects.}
}
\description{
Implementation of Fairness Cookbook in Causal Fairness Analysis
(Plecko & Bareinboim 2024). Uses only plain \code{R}.
}
\details{
The procedure takes the data as an input, together with
the causal graph given by the Standard Fairness Model, and outputs a causal
decomposition of the TV measure into direct, indirect, and spurious effects.
}
\examples{
\dontrun{
data <- faircause::berkeley

fcb <- fairness_cookbook(data, X = "gender", Z = character(0L), W = "dept",
                         Y = "admit", x0 = "Male", x1 = "Female")
fcb
}


}
\references{
Plecko, D. & Bareinboim, E. (2022).
Causal Fairness Analysis \cr
}
\author{
Drago Plecko
}
